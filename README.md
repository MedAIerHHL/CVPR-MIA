# CVPR-MIA

Recent papers about medical images published on CVPR. [[Github](https://github.com/MedAIerHHL/CVPR-MIA/)]

To complement or correct it, please contact me at **1729766533 [at] qq [dot] com** or **send a pull request** .

Last updated: 2024/04/04

## CVPR2024

### Image Reconstruction (图像重建)

- QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT Reconstruction. [[Paper](https://arxiv.org/abs/2402.17951v1)][Code][[Project](https://towzeur.github.io/QN-Mixer/)]
- Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI. [[Paper](https://arxiv.org/abs/2312.03102)][[Code](http://github.com/seannz/svr)]
- Structure-Aware Sparse-View X-ray 3D Reconstruction.[[Paper](https://arxiv.org/abs/2311.10959)][[Code](https://github.com/caiyuanhao1998/SAX-NeRF)]
- Progressive Divide-and-Conquer via Subsampling Decomposition for Accelerated MRI. [[Paper](https://arxiv.org/abs/2403.10064)][[Code](https://github.com/ChongWang1024/PDAC)]

### Image Resolution (图像超分)

- Learning Large-Factor EM Image Super-Resolution with Generative Priors. [Paper][Code]

### Image Registration (图像配准)

- Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration. [[Paper](https://arxiv.org/abs/2402.18933)]
- Correlation-aware Coarse-to-fine MLPs for Deformable Medical Image Registration. [Paper][[Code](https://github.com/jungeun122333/UVI-Net)]

### Image Segmentation (图像分割)

- PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology Segmentation. [[Paper](https://arxiv.org/abs/2402.19286)]
- Versatile Medical Image Segmentation Learned from Multi-Source Datasets via Model Self-Disambiguation. [[Paper](https://arxiv.org/abs/2311.10696)]
- Each Test Image Deserves A Specific Prompt: Continual Test-Time Adaptation for 2D Medical Image Segmentation. [[Paper](https://arxiv.org/abs/2311.18363)][[Code](https://github.com/Chen-Ziyang/VPTTA)]
- One-Prompt to Segment All Medical Images. [[Paper](https://arxiv.org/abs/2305.10300)][[Code](https://github.com/WuJunde/PromptUNet/tree/main)]
- Modality-agnostic Domain Generalizable Medical Image Segmentation by Multi-Frequency in Multi-Scale Attention. [Paper][Code][[Project](https://skawngus1111.github.io/MADGNet_project/)]
- Diversified and Personalized Multi-rater Medical Image Segmentation. [[Paper](https://arxiv.org/pdf/2212.00601)][[Code](https://github.com/ycwu1997/D-Persona)]
- MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling. [[Paper](https://arxiv.org/abs/2303.09373)][Code]
- Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation. [Paper][Code]
- Cross-dimension Affinity Distillation for 3D EM Neuron Segmentation. [Paper][Code]
- ToNNO: Tomographic Reconstruction of a Neural Network’s Output for Weakly Supervised Segmentation of 3D Medical Images.[Paper][Code]
- Versatile Medical Image Segmentation Learned from Multi-Source Datasets via Model Self-Disambiguation. [[Paper](https://arxiv.org/abs/2311.10696)][Code]
- Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Anthropic Prior Knowledge. [Paper][Code]
- Tyche: Stochastic in Context Learning for Universal Medical Image Segmentation. [[Paper](https://arxiv.org/abs/2401.13650)][[Code](https://github.com/mariannerakic/tyche/)]
- Constructing and Exploring Intermediate Domains in Mixed Domain Semi-supervised Medical Image Segmentation. [Paper][Code]
- S2VNet: Universal Multi-Class Medical Image Segmentation via Clustering-based Slice-to-Volume Propagation. [Paper][Code]
- EMCAD: Efficient Multi-scale Convolutional Attention Decoding for Medical Image Segmentation.[Paper][Code]
- Training Like a Medical Resident: Context-Prior Learning Toward Universal Medical Image Segmentation.[[Paper](https://arxiv.org/abs/2306.02416)][[Code](https://github.com/yhygao/universal-medical-image-segmentation)]

### Image Generation (图像生成)

- Learned representation-guided diffusion models for large-image generation. [[Paper](https://arxiv.org/abs/2312.07330)]
- MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant. [[Paper](https://arxiv.org/html/2403.04290v1)]
- Towards Generalizable Tumor Synthesis. [[Paper](https://arxiv.org/abs/2402.19470v1)][[Code](https://github.com/MrGiovanni/DiffTumor)]
- Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images. [[Paper](https://arxiv.org/abs/2404.01464)][[Code](https://github.com/jungeun122333/UVI-Net)]

### Image Classification (图像分类)

- Systematic comparison of semi-supervised and self-supervised learning for medical image classification. [[Paper](https://arxiv.org/abs/2307.08919v2)][[Code](https://github.com/tufts-ml/SSL-vs-SSL-benchmark)]
- PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection. [Paper][Code]
- Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images. [[Paper](https://arxiv.org/abs/2403.12570)][[Code](https://github.com/MediaBrain-SJTU/MVFA-AD)]

### Federated Learning（联邦学习）

- Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts. [[Paper](https://arxiv.org/abs/2312.02567)]

### Medical Pre-training (预训练)

- VoCo: A Simple-yet-Effective Volume Contrastive Learning Framework for 3D Medical Image Analysis. [[Paper](https://arxiv.org/abs/2402.17300)][[Code](https://github.com/Luffy03/VoCo)]
- MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning. [[Paper](https://arxiv.org/abs/2402.02045)]
- Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning. [[Paper](https://arxiv.org/abs/2311.17597)][[Code](https://github.com/yeerwen/MedCoSS)]
- Bootstrapping Chest CT Image Understanding by Distilling Knowledge from X-ray Expert Models. [Paper][Code]
- Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding. [[Paper](https://arxiv.org/abs/2403.18271)][[Code](https://github.com/Cccccczh404/H-SAM)]

### Vision-Language Models (视觉-语言)

- PairAug: What Can Augmented Image-Text Pairs Do for Radiology? [Paper][Code]
- Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework. [[Paper](https://arxiv.org/abs/2403.07636)][[Code](https://github.com/HieuPhan33/MAVL)]
- Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images. [[Paper](https://arxiv.org/abs/2403.12570)][[Code](https://github.com/MediaBrain-SJTU/MVFA-AD)]
- OmniMedVQA: A New Large-Scale Comprehensive Evaluation Benchmark for Medical LVLM. [[Paper](https://arxiv.org/abs/2402.09181)][Code]
- CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification. [[Paper](https://arxiv.org/abs/2402.17417)][Code]

### Foundation Models (基础模型)

- Low-Rank Knowledge Decomposition for Medical Foundation Models. [Paper][Code]

### Computational Pathology (计算病理)

- Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction. [[Paper](https://arxiv.org/abs/2402.19326)]
- Feature Re-Embedding: Towards Foundation Model-Level Performance in Computational Pathology. [[Paper](https://arxiv.org/abs/2402.17228)][[Code](https://github.com/DearCaat/RRT-MIL)]
- PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology Segmentation. [[Paper](https://arxiv.org/abs/2402.19286)]
- ChAda-ViT: Channel Adaptive Attention for Joint Representation Learning of Heterogeneous Microscopy Images. [[Paper](https://arxiv.org/abs/2311.15264)][[Code](https://github.com/nicoboou/chada_vit)]
- SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel Histopathology. [[Paper](https://arxiv.org/abs/2312.15010)][Code]

### Others

- Seeing Unseen: Discover Novel Biomedical Concepts via Geometry-Constrained Probabilistic Modeling. [[Paper](https://arxiv.org/html/2403.01053v2)]
- FocusMAE: Gallbladder Cancer Detection from Ultrasound Videos with Focused Masked Autoencoders. [[Paper](https://arxiv.org/abs/2403.08848)][[Code](https://github.com/sbasu276/FocusMAE)]
